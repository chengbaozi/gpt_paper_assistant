 1. New methodological improvements to self-supervised learning in computer vision.
    - Relevant: papers that propose new self-supervised approaches for images, aiming to improve existing methods, or analyzing them. Usually these papers will mention a pretext task used to pretrain the neural networks resulting in higher performance when fine-tuing on the down-stream tasks.
    - Not relevant: papers that apply existing self-supervised learning to computer vision tasks in the specific field, such as medical images, remote sensing, pedestrian re-identification and so on.
 In suggesting papers to your friend, remember that he enjoys papers on self-supervised learning, representation learning, robotics and computer vision.
 Your friend also enjoys papers on video segmentation and exploration on transfer learning between modalities.
 He does not want to read papers that are about primarily applications of methods to specific domains.
